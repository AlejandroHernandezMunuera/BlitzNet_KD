# BlitzNet_Knowledge_Distillation
Knowledge distillation is introduced in a multi-task neural network. The NN used in this set up are: BlitzNet(student), Faster R-CNN(object detection tutor) and Mask R-CNN(semantic segmentation tutor)
